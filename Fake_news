import numpy as np
import pandas as pd
import itertools
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from xgboost import XGBClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm
from sklearn.tree import DecisionTreeClassifier
from src.clustering import KMeans
from sklearn.linear_model import SGDClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
df=pd.read_csv('D:\\Internship\\Revidly\\Task3\\news\\news.csv')
df.shape
df.head()
df.label.head()
x_train,x_test,y_train,y_test=train_test_split(df['text'],labels, test_size=0.2, random_state=7)
print(x_test)
tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)
labels=df.label
tfidf_train=tfidf_vectorizer.fit_transform(x_train) 
tfidf_test=tfidf_vectorizer.transform(x_test)
print(tfidf_train)
#implementing logistic regression
clf=LogisticRegression()
clf.fit(tfidf_train,y_train)
print ('score Scikit learn: ', clf.score(x_test,x_test))
y_pred=clf.predict(tfidf_test)
score=accuracy_score(y_test,y_pred)
print(f'Accuracy: {round(score*100,2)}%')
confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])

#using passive agressive classifier
pac=PassiveAggressiveClassifier(max_iter=50)
pac.fit(tfidf_train,y_train)
y_pred=pac.predict(tfidf_test)
score=accuracy_score(y_test,y_pred)
print(f'Accuracy: {round(score*100,2)}%')
confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])

#Using Multinomial NB
mnb=MultinomialNB()
mnb.fit(tfidf_train,y_train)
y_pred=mnb.predict(tfidf_test)
score=accuracy_score(y_test,y_pred)
print(f'Accuracy: {round(score*100,2)}%')
confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])

#With svm
svc=svm.LinearSVC()
svc.fit(tfidf_train,y_train)
y_pred=svc.predict(tfidf_test)
score=accuracy_score(y_test,y_pred)
print(f'Accuracy: {round(score*100,2)}%')
confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])

#Randomforest
rf=RandomForestClassifier()
rf.fit(tfidf_train,y_train)
y_pred=rf.predict(tfidf_test)
score=accuracy_score(y_test,y_pred)
print(f'Accuracy: {round(score*100,2)}%')
confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])

#SGDC Classifier
sgdc=SGDClassifier()
sgdc.fit(tfidf_train,y_train)
y_pred=sgdc.predict(tfidf_test)
score=accuracy_score(y_test,y_pred)
print(f'Accuracy: {round(score*100,2)}%')
confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])

#KNeighbour Classifier
classifier = KNeighborsClassifier(n_neighbors=2)
classifier.fit(tfidf_train,y_train)
y_pred=classifier.predict(tfidf_test)
score=accuracy_score(y_test,y_pred)
print(f'Accuracy: {round(score*100,2)}%')
confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])

#DecisionTree
DT=DecisionTreeClassifier()
DT.fit(tfidf_train,y_train)
y_pred=DT.predict(tfidf_test)
score=accuracy_score(y_test,y_pred)
print(f'Accuracy: {round(score*100,2)}%')
confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])

#XGBoost
xgb_clf = XGBClassifier()
xgb_clf.fit(tfidf_train,y_train)
y_pred=xgb_clf.predict(tfidf_test)
score=accuracy_score(y_test,y_pred)
print(f'Accuracy: {round(score*100,2)}%')
confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])

#AdaBoost
ada= AdaBoostClassifier()
ada.fit(tfidf_train,y_train)
y_pred=ada.predict(tfidf_test)
score=accuracy_score(y_test,y_pred)
print(f'Accuracy: {round(score*100,2)}%')
confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])
